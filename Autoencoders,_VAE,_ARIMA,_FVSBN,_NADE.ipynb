{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZGlkIMRO0AN"
   },
   "source": [
    "# EXP 1 -Implement a basic autoencoder using TensorFlow or PyTorch and train it on a dataset like MNIST for image reconstruction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3XSopYSQZGv"
   },
   "source": [
    "- Dataset – Uses MNIST (28×28 handwritten digits) loaded with PyTorch DataLoader.\n",
    "\n",
    "- Models – Implements two autoencoders:\n",
    "\n",
    "- Fully Connected (FC) – compresses image to 3-dim latent space.\n",
    "\n",
    "- Convolutional (CNN) – uses conv + transpose conv layers for better reconstructions.\n",
    "\n",
    "- Training – Optimizer = Adam, loss = MSE (backprop), but also tracks MAE, BCE, SSIM, PSNR.\n",
    "\n",
    "- Evaluation – Prints metrics per epoch and compares reconstruction quality.\n",
    "\n",
    "- Visualization – Displays original images (top) vs. reconstructed images (bottom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KV-s-XS0zvop",
    "outputId": "77831b3e-732f-40a6-dbae-07cc6cd5842d"
   },
   "outputs": [],
   "source": [
    "!pip install pytorch-msssim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 805
    },
    "id": "4lRJzaQQ62mk",
    "outputId": "b0f0c386-80a9-40a4-c36e-656f41cd61cb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "try:\n",
    "    from pytorch_msssim import ssim\n",
    "except:\n",
    "    !pip install pytorch-msssim\n",
    "    from pytorch_msssim import ssim\n",
    "\n",
    "batch_size = 128\n",
    "lr = 1e-3\n",
    "epochs = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "class FCAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 128), nn.ReLU(True),\n",
    "            nn.Linear(128, 64), nn.ReLU(True),\n",
    "            nn.Linear(64, 12), nn.ReLU(True),\n",
    "            nn.Linear(12, 3)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12), nn.ReLU(True),\n",
    "            nn.Linear(12, 64), nn.ReLU(True),\n",
    "            nn.Linear(64, 128), nn.ReLU(True),\n",
    "            nn.Linear(128, 28*28), nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out.view(-1, 1, 28, 28)\n",
    "\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1), nn.ReLU(True),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1), nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, 7)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 7), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1), nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "mae_loss = nn.L1Loss()\n",
    "bce_loss = nn.BCELoss()\n",
    "\n",
    "def compute_psnr(mse):\n",
    "    if mse == 0: return float(\"inf\")\n",
    "    return 20 * math.log10(1.0 / math.sqrt(mse))\n",
    "\n",
    "def train(model, name):\n",
    "    model.to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train()\n",
    "        total_mse = total_mae = total_bce = total_ssim = 0\n",
    "        for imgs, _ in train_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            opt.zero_grad()\n",
    "            outs = model(imgs)\n",
    "            loss_mse = mse_loss(outs, imgs)\n",
    "            loss_mae = mae_loss(outs, imgs)\n",
    "            loss_bce = bce_loss(outs, imgs)\n",
    "            loss_ssim = ssim(outs, imgs, data_range=1.0, size_average=True)\n",
    "            loss_mse.backward()\n",
    "            opt.step()\n",
    "            total_mse += loss_mse.item()\n",
    "            total_mae += loss_mae.item()\n",
    "            total_bce += loss_bce.item()\n",
    "            total_ssim += loss_ssim.item()\n",
    "        avg_mse = total_mse/len(train_loader)\n",
    "        avg_mae = total_mae/len(train_loader)\n",
    "        avg_bce = total_bce/len(train_loader)\n",
    "        avg_ssim = total_ssim/len(train_loader)\n",
    "        avg_psnr = compute_psnr(avg_mse)\n",
    "        print(f\"{name} Epoch {ep}/{epochs} | MSE: {avg_mse:.4f} | MAE: {avg_mae:.4f} | BCE: {avg_bce:.4f} | PSNR: {avg_psnr:.2f} | SSIM: {avg_ssim:.4f}\")\n",
    "    return model\n",
    "\n",
    "def show_reconstructions(model, title):\n",
    "    model.eval()\n",
    "    imgs, _ = next(iter(train_loader))\n",
    "    imgs = imgs.to(device)\n",
    "    with torch.no_grad():\n",
    "        recons = model(imgs)\n",
    "    imgs, recons = imgs[:8].cpu(), recons[:8].cpu()\n",
    "    fig, axes = plt.subplots(2, 8, figsize=(15, 3))\n",
    "    for i in range(8):\n",
    "        axes[0,i].imshow(imgs[i].squeeze(), cmap=\"gray\"); axes[0,i].axis(\"off\")\n",
    "        axes[1,i].imshow(recons[i].squeeze(), cmap=\"gray\"); axes[1,i].axis(\"off\")\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "fc_model = train(FCAutoencoder(), \"FC NN Autoencoder\")\n",
    "cnn_model = train(ConvAutoencoder(), \"CNN Autoencoder\")\n",
    "\n",
    "print(\"\\nVisualizing reconstructions...\\n\")\n",
    "show_reconstructions(fc_model, \"FC Autoencoder: Original (top) vs Recon (bottom)\")\n",
    "show_reconstructions(cnn_model, \"CNN Autoencoder: Original (top) vs Recon (bottom)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnt-OPUblNW-"
   },
   "source": [
    "# EXP 2 - Explore different regularization techniques such as L1/L2 regularization or dropout and compare their effects on the autoencoder's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydN344kCQz4W"
   },
   "source": [
    "- Dataset – Loads MNIST, flattens each image to 784-dim vectors, normalizes pixel values to [0,1].\n",
    "\n",
    "- Models – Builds four autoencoders:\n",
    "\n",
    "- Baseline (no regularization)\n",
    "\n",
    "- L1 regularized (sparse encoding)\n",
    "\n",
    "- L2 regularized (weights penalty)\n",
    "\n",
    "- Dropout regularized (randomly drops neurons).\n",
    "\n",
    "- Training – Each model is trained for 10 epochs on MNIST with MSE loss and Adam optimizer.\n",
    "\n",
    "- Evaluation – Validation loss is recorded to compare reconstruction performance.\n",
    "\n",
    "- Visualization – Plots a line graph of validation loss across epochs to show the effect of regularization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5CGoOOymPREj",
    "outputId": "b457cf33-1311-48cb-821a-ec49b2c83289"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "input_dim = 784  # e.g., flattened MNIST\n",
    "encoding_dim = 32\n",
    "\n",
    "input_img = keras.Input(shape=(input_dim,))\n",
    "# Basic autoencoder (no reg)\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
    "decoded = layers.Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "encoded_l1 = layers.Dense(\n",
    "    encoding_dim,\n",
    "    activation='relu',\n",
    "    activity_regularizer=regularizers.l1(1e-5)\n",
    ")(input_img)\n",
    "decoded_l1 = layers.Dense(input_dim, activation='sigmoid')(encoded_l1)\n",
    "\n",
    "autoencoder_l1 = keras.Model(input_img, decoded_l1)\n",
    "autoencoder_l1.compile(optimizer='adam', loss='mse')\n",
    "encoded_l2 = layers.Dense(\n",
    "    encoding_dim,\n",
    "    activation='relu',\n",
    "    activity_regularizer=regularizers.l2(1e-4)\n",
    ")(input_img)\n",
    "decoded_l2 = layers.Dense(input_dim, activation='sigmoid')(encoded_l2)\n",
    "\n",
    "autoencoder_l2 = keras.Model(input_img, decoded_l2)\n",
    "autoencoder_l2.compile(optimizer='adam', loss='mse')\n",
    "encoded_do = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
    "dropout = layers.Dropout(0.5)(encoded_do)\n",
    "decoded_do = layers.Dense(input_dim, activation='sigmoid')(dropout)\n",
    "\n",
    "autoencoder_do = keras.Model(input_img, decoded_do)\n",
    "autoencoder_do.compile(optimizer='adam', loss='mse')\n",
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(-1, input_dim).astype('float32') / 255.\n",
    "x_test = x_test.reshape(-1, input_dim).astype('float32') / 255.\n",
    "\n",
    "history_baseline = autoencoder.fit(x_train, x_train,\n",
    "                                   epochs=10, batch_size=256,\n",
    "                                   shuffle=True, validation_data=(x_test, x_test))\n",
    "\n",
    "history_l1 = autoencoder_l1.fit(x_train, x_train,\n",
    "                               epochs=10, batch_size=256,\n",
    "                               shuffle=True, validation_data=(x_test, x_test))\n",
    "\n",
    "history_l2 = autoencoder_l2.fit(x_train, x_train,\n",
    "                               epochs=10, batch_size=256,\n",
    "                               shuffle=True, validation_data=(x_test, x_test))\n",
    "\n",
    "history_do = autoencoder_do.fit(x_train, x_train,\n",
    "                               epochs=10, batch_size=256,\n",
    "                               shuffle=True, validation_data=(x_test, x_test))\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(history_baseline.history['val_loss'], label='No Reg')\n",
    "plt.plot(history_l1.history['val_loss'], label='L1')\n",
    "plt.plot(history_l2.history['val_loss'], label='L2')\n",
    "plt.plot(history_do.history['val_loss'], label='Dropout')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Regularization Effects on Autoencoder Performance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n2du_FSql9oJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9S2Flrpdl9X8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3h-BoQnkPRlI"
   },
   "source": [
    "# EXP 3 - Implement a variational autoencoder (VAE) and train it on a dataset like FashionMNIST to generate new images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2_Aj1uHRJco"
   },
   "source": [
    "- Dataset – Uses FashionMNIST (28×28 grayscale images), loaded with PyTorch DataLoader.\n",
    "\n",
    "- Model (VAE) – Encoder outputs mean (μ) and log-variance (logσ²), reparameterization trick samples latent vector z, decoder reconstructs image.\n",
    "\n",
    "- Loss Function – Combines BCE (reconstruction error) + KLD (regularization) to match latent space with normal distribution.\n",
    "\n",
    "- Training – Optimizer = Adam, trained for 10 epochs, prints Total Loss, BCE, and KLD per epoch.\n",
    "\n",
    "- Visualization – Shows original FashionMNIST images (top row) vs. reconstructed images (bottom row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 533
    },
    "id": "9EJeA_-8PUb8",
    "outputId": "5ae51f35-3857-49b3-ca40-26ccff91ae4e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28 * 28, 400),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(400, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(400, latent_dim)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 28 * 28),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_encoded = self.encoder(x)\n",
    "        mu = self.fc_mu(x_encoded)\n",
    "        logvar = self.fc_logvar(x_encoded)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_decoded = self.decoder(z)\n",
    "        return x_decoded.view(-1, 1, 28, 28), mu, logvar\n",
    "\n",
    "def vae_loss_function(recon_x, x, mu, logvar):\n",
    "    bce = nn.functional.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return bce + kld, bce, kld\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    total_bce = 0\n",
    "    total_kld = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss, bce, kld = vae_loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        total_bce += bce.item()\n",
    "        total_kld += kld.item()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch}: Total Loss = {train_loss:.2f}, BCE = {total_bce:.2f}, KLD = {total_kld:.2f}\")\n",
    "\n",
    "def show_original_vs_reconstructed(model, data_loader, device):\n",
    "    model.eval()\n",
    "    data_iter = iter(data_loader)\n",
    "    images, _ = next(data_iter)\n",
    "    images = images.to(device)\n",
    "    with torch.no_grad():\n",
    "        recon, _, _ = model(images)\n",
    "    images = images.cpu()\n",
    "    recon = recon.cpu()\n",
    "    n = 8\n",
    "    comparison = torch.cat([images[:n], recon[:n]])\n",
    "    grid = make_grid(comparison, nrow=n)\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    plt.imshow(grid.permute(1, 2, 0))\n",
    "    plt.title(\"Top: Original | Bottom: Reconstructed\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_original_vs_reconstructed(model, train_loader, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGPBbg9lSPAL"
   },
   "source": [
    "# Exp - 4 - Implement a basic autoregressive model like the Fully Visible Sigmoid Belief Network (FVSBN) using PyTorch or TensorFlow and train it on a sequential dataset like time series data.\n",
    "\n",
    "- Data Cleaning & EDA – Loads housing dataset, cleans dates & percentages, and visualizes trends (histograms, line plots, boxplots).\n",
    "\n",
    "- ARIMA Forecasting – Builds ARIMA model on house price moving averages, forecasts future quarters with confidence bands.\n",
    "\n",
    "- Time-Series Windowing – Converts moving averages into normalized binary windows for sequential modeling.\n",
    "\n",
    "- FVSBN Model – Implements and trains a Fully Visible Sigmoid Belief Network (autoregressive model) on time-series windows.\n",
    "\n",
    "- Results – Generates synthetic windows of MA values and shows a correlation heatmap of features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LUw-QKuSZ1ir",
    "outputId": "5b9fce7c-946d-4cda-e88e-e038cc688027"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "df = pd.read_csv(\"1.csv\")\n",
    "print(\"Shape of dataset:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "print(\"\\nData Types:\\n\", df.dtypes)\n",
    "print(\"\\nMissing values:\\n\", df.isnull().sum())\n",
    "\n",
    "df['saledate'] = pd.to_datetime(df['saledate'], errors='coerce', dayfirst=True)\n",
    "df['MA'] = df['MA'].astype(str).str.replace('%','').astype(float)\n",
    "\n",
    "print(\"\\nSummary Stats (Numeric):\\n\", df.describe())\n",
    "print(\"\\nUnique values in categorical columns:\\n\")\n",
    "print(\"type:\", df['type'].unique())\n",
    "print(\"bedrooms:\", df['bedrooms'].unique())\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(df['MA'], bins=30, kde=True)\n",
    "plt.title(\"Distribution of Moving Average (MA)\")\n",
    "plt.xlabel(\"MA (%)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.countplot(x='type', data=df, palette='Set2')\n",
    "plt.title(\"Property Type Distribution\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.countplot(x='bedrooms', data=df, palette='Set1')\n",
    "plt.title(\"Number of Bedrooms Distribution\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.lineplot(x='saledate', y='MA', hue='type', data=df, marker='o')\n",
    "plt.title(\"Moving Average of Median Price Over Time\")\n",
    "plt.xlabel(\"Sale Date\")\n",
    "plt.ylabel(\"MA (%)\")\n",
    "plt.legend(title=\"Property Type\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAverage MA per property type:\\n\", df.groupby('type')['MA'].mean())\n",
    "print(\"\\nAverage MA per bedroom:\\n\", df.groupby('bedrooms')['MA'].mean())\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(x='bedrooms', y='MA', hue='type', data=df)\n",
    "plt.title(\"MA Distribution by Bedrooms & Property Type\")\n",
    "plt.show()\n",
    "\n",
    "df['saledate'] = pd.to_datetime(df['saledate'], errors='coerce', dayfirst=True)\n",
    "df['MA'] = df['MA'].astype(str).str.replace('%','').astype(float)\n",
    "df['MA'] = df['MA'].ffill()\n",
    "df_house = df[df['type']=='house']\n",
    "df_house = df_house.groupby('saledate')['MA'].mean().reset_index()\n",
    "df_house = df_house.set_index('saledate').resample('QE').mean()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(df_house['MA'], label='House MA')\n",
    "plt.title(\"House Median Price (Moving Average) Quarterly\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "model = sm.tsa.ARIMA(df_house['MA'], order=(1,1,1))\n",
    "results = model.fit()\n",
    "print(results.summary())\n",
    "\n",
    "forecast = results.get_forecast(steps=8)\n",
    "forecast_mean = forecast.predicted_mean\n",
    "forecast_ci = forecast.conf_int()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(df_house['MA'], label='Observed')\n",
    "plt.plot(forecast_mean, label='Forecast', color='red')\n",
    "plt.fill_between(forecast_ci.index, forecast_ci.iloc[:,0], forecast_ci.iloc[:,1], color='pink', alpha=0.3)\n",
    "plt.title(\"ARIMA Forecast for House Median Price (Quarterly)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "df = pd.read_csv(\"1.csv\")\n",
    "df.columns = df.columns.str.strip()\n",
    "df[\"saledate\"] = pd.to_datetime(df[\"saledate\"], errors=\"coerce\", dayfirst=True)\n",
    "df[\"MA\"] = df[\"MA\"].astype(str).str.replace(\"%\", \"\", regex=False).str.replace(\",\", \"\", regex=False).astype(float)\n",
    "df = df.dropna(subset=[\"saledate\", \"MA\"]).copy()\n",
    "df = df.sort_values(\"saledate\")\n",
    "df[\"type\"] = df[\"type\"].astype(str).str.lower().str.strip()\n",
    "df[\"bedrooms\"] = pd.to_numeric(df[\"bedrooms\"], errors=\"coerce\")\n",
    "\n",
    "ts = df[[\"saledate\", \"MA\"]].set_index(\"saledate\").resample(\"QE\").mean().ffill()\n",
    "print(f\"Quarterly points available: {len(ts)}\")\n",
    "\n",
    "WINDOW = 8\n",
    "series = ts[\"MA\"].values.astype(np.float32)\n",
    "s_min, s_max = series.min(), series.max()\n",
    "norm = (series - s_min) / (s_max - s_min) if s_max != s_min else np.zeros_like(series)\n",
    "threshold = np.nanmedian(norm)\n",
    "binary = (norm >= threshold).astype(np.float32)\n",
    "\n",
    "X = []\n",
    "for i in range(len(binary) - WINDOW + 1):\n",
    "    X.append(binary[i:i+WINDOW])\n",
    "X = np.stack(X, axis=0) if len(binary) >= WINDOW else np.empty((0, WINDOW), dtype=np.float32)\n",
    "if X.shape[0] == 0:\n",
    "    raise ValueError(\"Not enough quarterly points to create windows.\")\n",
    "X_t = torch.tensor(X, dtype=torch.float32)\n",
    "dataset = TensorDataset(X_t)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True, drop_last=False)\n",
    "print(f\"Training samples: {len(dataset)}, Vector dim (D): {WINDOW}\")\n",
    "\n",
    "class FVSBN(nn.Module):\n",
    "    def __init__(self, dim, hidden_size=128):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.hidden = nn.Linear(dim, hidden_size)\n",
    "        self.act = nn.ReLU()\n",
    "        self.out = nn.Linear(hidden_size, dim)\n",
    "        nn.init.zeros_(self.out.bias)\n",
    "    def forward(self, x, forward_mask=None):\n",
    "        x_masked = x * forward_mask if forward_mask is not None else x\n",
    "        h = self.act(self.hidden(x_masked))\n",
    "        return self.out(h)\n",
    "    def log_prob(self, x):\n",
    "        B, D = x.shape\n",
    "        total_lp = x.new_zeros(B)\n",
    "        for i in range(D):\n",
    "            mask = torch.zeros_like(x)\n",
    "            if i > 0:\n",
    "                mask[:, :i] = 1.0\n",
    "            logits = self.forward(x, forward_mask=mask)\n",
    "            logp_i = -nn.functional.binary_cross_entropy_with_logits(logits[:, i], x[:, i], reduction=\"none\")\n",
    "            total_lp += logp_i\n",
    "        return total_lp\n",
    "    @torch.no_grad()\n",
    "    def sample(self, n_samples=1):\n",
    "        samples = torch.zeros((n_samples, self.dim), device=next(self.parameters()).device)\n",
    "        for i in range(self.dim):\n",
    "            mask = torch.zeros_like(samples)\n",
    "            if i > 0:\n",
    "                mask[:, :i] = 1.0\n",
    "            logits = self.forward(samples, forward_mask=mask)\n",
    "            probs = torch.sigmoid(logits[:, i])\n",
    "            u = torch.rand_like(probs)\n",
    "            samples[:, i] = (u < probs).float()\n",
    "        return samples.cpu().numpy()\n",
    "\n",
    "D = WINDOW\n",
    "model = FVSBN(dim=D, hidden_size=128).to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "EPOCHS = 25\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    total_ll, n_seen = 0.0, 0\n",
    "    for (xb,) in dataloader:\n",
    "        xb = xb.to(device)\n",
    "        opt.zero_grad()\n",
    "        logp = model.log_prob(xb)\n",
    "        loss = -logp.mean()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_ll += logp.sum().item()\n",
    "        n_seen += xb.size(0)\n",
    "    avg_ll = total_ll / n_seen\n",
    "    print(f\"Epoch {epoch:02d} | Avg log p(x): {avg_ll:.4f} | NLL: {-avg_ll:.4f}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    gen_bin = model.sample(n_samples=5)\n",
    "low_val, high_val = 0.25, 0.75\n",
    "gen_norm = np.where(gen_bin < 0.5, low_val, high_val)\n",
    "gen_MA = gen_norm * (s_max - s_min) + s_min\n",
    "print(\"\\nGenerated binary windows (0/1):\")\n",
    "print(gen_bin)\n",
    "print(\"\\nGenerated MA (%) windows (approximate, using 25/75% mapping):\")\n",
    "print(np.round(gen_MA, 2))\n",
    "\n",
    "df['saledate'] = pd.to_datetime(df['saledate'], dayfirst=True, errors='coerce')\n",
    "df['quarter'] = df['saledate'].dt.to_period('Q').astype(str)\n",
    "df['quarter_num'] = pd.factorize(df['quarter'])[0] + 1\n",
    "df['type_num'] = df['type'].map({'house':0, 'unit':1})\n",
    "numeric_df = df[['MA', 'bedrooms', 'quarter_num', 'type_num']]\n",
    "corr = numeric_df.corr()\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Correlation Heatmap of Features\", fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CDeqkuslqiaR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KetTXT-gqiW8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PxVkpqAedVim"
   },
   "source": [
    "# EXP5 - Implement NADE and train it on a dataset like CIFAR-10 for image generation.\n",
    "\n",
    "\n",
    "\n",
    "- Dataset & Preprocessing – Loads the CIFAR-10 dataset, flattens each image (32×32×3 = 3072 pixels) for autoregressive modeling.\n",
    "\n",
    "- Masked Linear Layers – Uses custom MaskedLinear to enforce autoregressive constraints so that each pixel depends only on previous pixels.\n",
    "\n",
    "- FastNADE Model – Implements NADE with one hidden layer, applying masks to both input → hidden and hidden → output connections.\n",
    "\n",
    "- Training – Trains the model with binary cross-entropy loss to reconstruct images, optimizing with Adam.\n",
    "\n",
    "- Image Generation – Sequentially samples pixels one by one from the trained model to generate new synthetic CIFAR-10-like images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 690
    },
    "id": "7MKs7uxejX2g",
    "outputId": "6d63c6a5-f008-46b9-bc24-8f944cbc846f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "class MaskedLinear(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, mask):\n",
    "        super().__init__(in_features, out_features)\n",
    "        self.register_buffer('mask', mask)\n",
    "    def forward(self, x):\n",
    "        return nn.functional.linear(x, self.weight * self.mask, self.bias)\n",
    "\n",
    "class FastNADE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        mask_in = torch.tril(torch.ones(hidden_dim, input_dim))\n",
    "        self.fc1 = MaskedLinear(input_dim, hidden_dim, mask_in)\n",
    "        mask_out = torch.tril(torch.ones(input_dim, hidden_dim), diagonal=-1)\n",
    "        self.fc2 = MaskedLinear(hidden_dim, input_dim, mask_out)\n",
    "    def forward(self, x):\n",
    "        h = torch.sigmoid(self.fc1(x))\n",
    "        out = torch.sigmoid(self.fc2(h))\n",
    "        return out\n",
    "\n",
    "input_dim = 32*32*3\n",
    "hidden_dim = 500\n",
    "model = FastNADE(input_dim, hidden_dim).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, _ in train_loader:\n",
    "        images = images.view(images.size(0), -1).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "model.eval()\n",
    "n_samples = 16\n",
    "samples = torch.zeros(n_samples, input_dim, device=device)\n",
    "with torch.no_grad():\n",
    "    for i in range(input_dim):\n",
    "        out = model(samples)\n",
    "        samples[:, i] = (torch.rand(n_samples, device=device) < out[:, i]).float()\n",
    "samples = samples.view(n_samples, 3, 32, 32).cpu()\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(6,6))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(samples[i].permute(1,2,0))\n",
    "    ax.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aToRtuqNH_jO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
